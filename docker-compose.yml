version: "3.9"

# -----------------------------------------------------------------------------
#  The Podcaster – Local Podcast Automation Platform
# -----------------------------------------------------------------------------
# This compose file spins up every service required for end-to-end processing.
# Most services are optional during early development and can be commented out
# if you only want a subset of functionality.
# -----------------------------------------------------------------------------

services:

  # ---------------------------------------------------------------------------
  # FastAPI backend – REST API & task dispatcher
  # ---------------------------------------------------------------------------
  backend:
    build:
      context: ./backend
    container_name: podcaster-backend
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    volumes:
      - ./backend:/code
      - ./data:/data  # audio/video artifacts
      - ./test/Intro_Outro_test.mp3:/data/preloaded_test_files/Intro_Outro_test.mp3:ro
      - ./test/Main_Audio_test.wav:/data/preloaded_test_files/Main_Audio_test.wav:ro
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - OLLAMA_URL=${OLLAMA_URL}
      - PYTHONUNBUFFERED=1
    depends_on:
      - db
      - broker

  # ---------------------------------------------------------------------------
  # Celery worker – background heavy-lifting (FFmpeg, Whisper, etc.)
  # ---------------------------------------------------------------------------
  worker:
    build:
      context: ./backend
    container_name: podcaster-worker
    command: ["celery", "-A", "app.workers.tasks:celery_app", "worker", "--loglevel=info"]
    volumes:
      - ./backend:/code
      - ./data:/data
      - ./test/Intro_Outro_test.mp3:/data/preloaded_test_files/Intro_Outro_test.mp3:ro
      - ./test/Main_Audio_test.wav:/data/preloaded_test_files/Main_Audio_test.wav:ro
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - OLLAMA_URL=${OLLAMA_URL}
    depends_on:
      - broker
      - db

  # ---------------------------------------------------------------------------
  # Database – PostgreSQL 15
  # ---------------------------------------------------------------------------
  db:
    image: postgres:15-alpine
    container_name: podcaster-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: podcaster
      POSTGRES_USER: podcaster
      POSTGRES_PASSWORD: podcaster
    volumes:
      - pgdata:/var/lib/postgresql/data

  # ---------------------------------------------------------------------------
  # Redis – broker & result backend
  # ---------------------------------------------------------------------------
  broker:
    image: redis:7-alpine
    container_name: podcaster-redis
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Ollama – local LLM server (CPU or GPU)
  # ---------------------------------------------------------------------------
 #  ollama:
 #    image: ollama/ollama:latest
 #    container_name: podcaster-ollama
 #    restart: unless-stopped
 #    ports:
 #      - "11434:11434"
 #    volumes:
 #      - ollama_models:/root/.ollama

  # ---------------------------------------------------------------------------
  # n8n – workflow automation (optional, comment until Milestone 6)
  # ---------------------------------------------------------------------------
 #  n8n:
 #    image: n8nio/n8n:latest
 #    container_name: podcaster-n8n
 #    restart: unless-stopped
 #    ports:
 #      - "5678:5678"
 #    environment:
 #      - N8N_BASIC_AUTH_ACTIVE=true   # <-- Change credentials in .env
 #      - N8N_BASIC_AUTH_USER=admin
 #      - N8N_BASIC_AUTH_PASSWORD=admin
 #    volumes:
 #      - n8n_data:/home/node/.n8n
 #    depends_on:
 #      - db

  # ---------------------------------------------------------------------------
  # Waveform Generator – Node.js/Puppeteer service for generating waveform images
  # ---------------------------------------------------------------------------
  waveform_generator:
    build:
      context: ./waveform-generator
    container_name: waveform_generator
    environment:
      - NODE_ENV=production
    volumes:
      # Mount a volume for output files if generated inside the container
      # and needed by other services or host.
      - ./generated_waveforms:/usr/src/app/generated_waveforms
      # Mount test audio if needed for direct testing
      - ./test:/test_data
    # Restart policy might not be needed if run on-demand
    # restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Front-end – placeholder Nginx serving AudioMass static build
  # ---------------------------------------------------------------------------
  frontend:
    image: nginx:1.25-alpine
    container_name: podcaster-frontend
    ports:
      - "${FRONTEND_PORT:-8080}:80" # Default to 8080 if FRONTEND_PORT is not set
    volumes:
      - ./frontend:/usr/share/nginx/html:ro # Static front-end SPA
      - ./frontend/nginx.conf:/etc/nginx/conf.d/default.conf:ro # Custom proxy & upload limits

volumes:
  pgdata:
  ollama_models:
  n8n_data:
